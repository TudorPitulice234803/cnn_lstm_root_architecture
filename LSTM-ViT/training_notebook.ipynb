{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f778c6d1-dc7d-4b7a-a1d9-db787692e7a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-05 11:41:17.809076: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-08-05 11:41:17.847540: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-08-05 11:41:17.847593: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-08-05 11:41:17.848954: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-08-05 11:41:17.855783: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "import tensorflow as tf\n",
    "from model import lstm_vit\n",
    "from helpers import f1\n",
    "import warnings\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from data_loader import data_generator\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    tf.config.set_visible_devices(gpus[0], 'GPU')\n",
    "    \n",
    "    tf.config.experimental.set_memory_growth(gpus[0], True)\n",
    "\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "K.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ab7c927b-113d-410f-b70b-f46eba804307",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-05 11:41:21.979019: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 46672 MB memory:  -> device: 0, name: NVIDIA RTX 6000 Ada Generation, pci bus id: 0000:21:00.0, compute capability: 8.9\n",
      "WARNING: Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING: Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING: Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"LSTM_ViT\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 15, 256, 256, 3   0         \n",
      "                             )]                                  \n",
      "                                                                 \n",
      " temporal_encoding (TimeDis  (None, 15, 16, 16, 256)   2871776   \n",
      " tributed)                                                       \n",
      "                                                                 \n",
      " spatial_pooling (TimeDistr  (None, 15, 256)           0         \n",
      " ibuted)                                                         \n",
      "                                                                 \n",
      " temporal_lstm (Bidirection  (None, 15, 128)           164352    \n",
      " al)                                                             \n",
      "                                                                 \n",
      " spatial_projection (TimeDi  (None, 15, 65536)         8454144   \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      " spatial_reshape (TimeDistr  (None, 15, 16, 16, 256)   0         \n",
      " ibuted)                                                         \n",
      "                                                                 \n",
      " upsample_1 (TimeDistribute  (None, 15, 32, 32, 64)    262144    \n",
      " d)                                                              \n",
      "                                                                 \n",
      " time_distributed (TimeDist  (None, 15, 32, 32, 64)    256       \n",
      " ributed)                                                        \n",
      "                                                                 \n",
      " time_distributed_1 (TimeDi  (None, 15, 32, 32, 64)    0         \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      " upsample_2 (TimeDistribute  (None, 15, 64, 64, 32)    32768     \n",
      " d)                                                              \n",
      "                                                                 \n",
      " time_distributed_2 (TimeDi  (None, 15, 64, 64, 32)    128       \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      " time_distributed_3 (TimeDi  (None, 15, 64, 64, 32)    0         \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      " upsample_3 (TimeDistribute  (None, 15, 128, 128, 16   8192      \n",
      " d)                          )                                   \n",
      "                                                                 \n",
      " time_distributed_4 (TimeDi  (None, 15, 128, 128, 16   64        \n",
      " stributed)                  )                                   \n",
      "                                                                 \n",
      " time_distributed_5 (TimeDi  (None, 15, 128, 128, 16   0         \n",
      " stributed)                  )                                   \n",
      "                                                                 \n",
      " upsample_4 (TimeDistribute  (None, 15, 256, 256, 8)   2048      \n",
      " d)                                                              \n",
      "                                                                 \n",
      " time_distributed_6 (TimeDi  (None, 15, 256, 256, 8)   32        \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      " time_distributed_7 (TimeDi  (None, 15, 256, 256, 8)   0         \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      " final_segmentation (TimeDi  (None, 15, 256, 256, 1)   9         \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 11795913 (45.00 MB)\n",
      "Trainable params: 11794457 (44.99 MB)\n",
      "Non-trainable params: 1456 (5.69 KB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = lstm_vit()\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=[f1])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "394f5acd-f6b0-46df-80e9-474d004e9906",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_img_path = 'data_v3_processed/train/images/images'\n",
    "train_masks_path = 'data_v3_processed/train/masks/masks'\n",
    "\n",
    "val_img_path = 'data_v3_processed/val/images/images'\n",
    "val_masks_path = 'data_v3_processed/val/masks/masks'\n",
    "\n",
    "train_gen = data_generator(train_img_path, train_masks_path, 32)\n",
    "val_gen = data_generator(val_img_path, val_masks_path, 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eac4d2a0-c7e0-40b0-be6f-155abeef8ba4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building sequence list and filtering empty sequences...\n",
      "Total valid sequences: 220\n",
      "Skipped empty sequences: 270\n",
      "Reverse time order: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-05 11:41:40.399721: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8906\n",
      "2025-08-05 11:41:47.628999: I external/local_xla/xla/service/service.cc:168] XLA service 0x7f533568cdf0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2025-08-05 11:41:47.629046: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA RTX 6000 Ada Generation, Compute Capability 8.9\n",
      "2025-08-05 11:41:47.633858: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1754394107.755599    2978 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6000/6000 [==============================] - 7706s 1s/step - loss: 0.0176 - f1: 0.3163\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_gen,\n",
    "                    epochs=1,\n",
    "                    batch_size=32,\n",
    "                    steps_per_epoch=6000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ce1d8c0c-f614-4008-8f56-8ca571663c38",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"lstm_vit_model.h5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
